{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a530fdef",
   "metadata": {},
   "source": [
    "# Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6588693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "import scipy.signal\n",
    "import os\n",
    "from MFCC import concatenate_mfcc_deltas,compute_mfcc, compute_delta\n",
    "import librosa\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c286b",
   "metadata": {},
   "source": [
    "# Loading Audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78af3de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: turn_off_the_lights_30.wav\n",
      "File not found: what_time_is_it_30.wav\n",
      "File not found: stop_music_30.wav\n"
     ]
    }
   ],
   "source": [
    "def load_audio_names(name):\n",
    "    audio_files = []\n",
    "    for i in range(1,31):\n",
    "        filename = f'{name}_{i}.wav'\n",
    "        pathname = f'./{name}/{name}_{i}.wav'\n",
    "        if os.path.isfile(pathname):\n",
    "            audio, sr = librosa.load(pathname, sr=None)  # Load audio file with original sampling rate\n",
    "            audio_files.append((filename, audio, sr))\n",
    "        else:\n",
    "            print(f'File not found: {filename}')\n",
    "    return audio_files\n",
    "\n",
    "odessa_files = load_audio_names('Odessa')\n",
    "lights_off_files = load_audio_names('turn_off_the_lights')\n",
    "lights_on_files = load_audio_names('turn_on_the_lights')\n",
    "time_files = load_audio_names('what_time_is_it')\n",
    "play_music_files = load_audio_names('play_music')\n",
    "stop_music_files = load_audio_names('stop_music')\n",
    "\n",
    "all_files = odessa_files + lights_off_files + lights_on_files + time_files + play_music_files + stop_music_files\n",
    "\n",
    "def load_audio_filenames_from_txt(file_name):\n",
    "    if not os.path.isfile(file_name):\n",
    "        raise FileNotFoundError(f\"The file {file_name} does not exist in the directory.\")\n",
    "    \n",
    "    with open(file_name, 'r') as file:\n",
    "        audio_filenames = [line.strip() for line in file if line.strip()]\n",
    "    return audio_filenames\n",
    "\n",
    "def find_matching_files(train_filenames, all_files):\n",
    "    matching_files = []\n",
    "    for train_filename in train_filenames:\n",
    "        for filename, audio, sr in all_files:\n",
    "            if train_filename == filename:\n",
    "                matching_files.append((filename, audio, sr))\n",
    "    return matching_files\n",
    "\n",
    "train = load_audio_filenames_from_txt('train.txt')\n",
    "train_files  = find_matching_files(train, all_files)\n",
    "\n",
    "data_train = { \"Odessa\": [], \"turn_on\":[], \"turn_off\": [], \"play_music\": [], \"stop_music\": [], \"time\": []}\n",
    "odessa = []\n",
    "turn_on = []\n",
    "turn_off = []\n",
    "play_music = []\n",
    "stop_music = []\n",
    "time = []\n",
    "M = 2\n",
    "fs = 16000\n",
    "\n",
    "for i in train_files:\n",
    "    if i[0].startswith(\"Odessa\"):\n",
    "        mfcc_features = compute_mfcc(np.array(i[1]), sample_rate=fs)\n",
    "        delta_mfcc = compute_delta(mfcc_features, M)\n",
    "        concatenate_features = concatenate_mfcc_deltas(mfcc_features, delta_mfcc, M)\n",
    "        odessa.append(concatenate_features)\n",
    "    elif i[0].startswith(\"what\"):\n",
    "        mfcc_features = compute_mfcc(np.array(i[1]), sample_rate=fs)\n",
    "        delta_mfcc = compute_delta(mfcc_features, M)\n",
    "        concatenate_features = concatenate_mfcc_deltas(mfcc_features, delta_mfcc, M)\n",
    "        time.append(concatenate_features)\n",
    "    elif i[0].startswith(\"turn_on\"):\n",
    "        mfcc_features = compute_mfcc(np.array(i[1]), sample_rate=fs)\n",
    "        delta_mfcc = compute_delta(mfcc_features, M)\n",
    "        concatenate_features = concatenate_mfcc_deltas(mfcc_features, delta_mfcc, M)\n",
    "        turn_on.append(concatenate_features)\n",
    "    elif i[0].startswith(\"turn_off\"):\n",
    "        mfcc_features = compute_mfcc(np.array(i[1]), sample_rate=fs)\n",
    "        delta_mfcc = compute_delta(mfcc_features, M)\n",
    "        concatenate_features = concatenate_mfcc_deltas(mfcc_features, delta_mfcc, M)\n",
    "        turn_off.append(concatenate_features)\n",
    "    elif i[0].startswith(\"play_music\"):\n",
    "        mfcc_features = compute_mfcc(np.array(i[1]), sample_rate=fs)\n",
    "        delta_mfcc = compute_delta(mfcc_features, M)\n",
    "        concatenate_features = concatenate_mfcc_deltas(mfcc_features, delta_mfcc, M)\n",
    "        play_music.append(concatenate_features)\n",
    "    elif i[0].startswith(\"stop_music\"):\n",
    "        mfcc_features = compute_mfcc(np.array(i[1]), sample_rate=fs)\n",
    "        delta_mfcc = compute_delta(mfcc_features, M)\n",
    "        concatenate_features = concatenate_mfcc_deltas(mfcc_features, delta_mfcc, M)\n",
    "        stop_music.append(concatenate_features)\n",
    "\n",
    "        \n",
    "data_train[\"Odessa\"] = np.array(odessa)\n",
    "data_train[\"turn_off\"] = np.array(turn_off)\n",
    "data_train[\"turn_on\"] = np.array(turn_on)\n",
    "data_train[\"play_music\"] = np.array(play_music)\n",
    "data_train[\"stop_music\"] = np.array(stop_music)\n",
    "data_train[\"time\"] = np.array(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df7665",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "171b4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(model, data):\n",
    "    _, _, _, loglik, _ = model.forwardbackward(model.pi, model.A, model.obs_probs(data.T, model.means.T, model.vars.T))\n",
    "    return loglik\n",
    "\n",
    "# def train_models(data_train, global_mu, global_var, num_states, pi):\n",
    "\n",
    "#     models = {}\n",
    "#     for label, states in num_states.items():\n",
    "#         mu_label = global_mu[label]\n",
    "#         var_label = global_var[label]\n",
    "#         model = HMM_new(num_states=states, num_features=len(mu_label), global_mean=mu_label, global_variance=var_label)\n",
    "#         prior, a_ij, mu, sigma = model.hmm_train(data_train[label], max_iter=100, pi = pi[label])\n",
    "#         model.pi = prior\n",
    "#         model.A = a_ij\n",
    "#         model.means = mu\n",
    "#         model.vars = sigma\n",
    "#         models[label] = model\n",
    "#         print(f'Trained model for {label}')\n",
    "    \n",
    "#     return models\n",
    "\n",
    "\n",
    "def evaluate_models(models, data_val):\n",
    "    results = {}\n",
    "    accuracy_per_label = {}\n",
    "\n",
    "    for true_label, sequences in data_val.items():\n",
    "        correct_predictions = 0\n",
    "        total_sequences = len(sequences)\n",
    "        \n",
    "        for sequence in sequences:\n",
    "            loglikelihoods = {model_label: compute_log_likelihood(model, sequence) for model_label, model in models.items()}\n",
    "            predicted_label = max(loglikelihoods, key=loglikelihoods.get)\n",
    "            \n",
    "            if predicted_label == true_label:\n",
    "                correct_predictions += 1\n",
    "            else:\n",
    "                print(f\"{true_label}  {predicted_label}\")\n",
    "\n",
    "        accuracy_per_label[true_label] = correct_predictions / total_sequences if total_sequences > 0 else 0\n",
    "\n",
    "    # Print results and accuracy per label\n",
    "    for true_label, accuracy in accuracy_per_label.items():\n",
    "        print(f\"Label: {true_label}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return accuracy_per_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08643023",
   "metadata": {},
   "source": [
    "# GMM-HMM class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ffcb47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM_GMM:\n",
    "    def __init__(self, num_states, num_features, num_mix):\n",
    "        self.num_states = num_states\n",
    "        self.num_features = num_features\n",
    "        self.num_mix = num_mix\n",
    "\n",
    "        self.A = self.make_leftright_transmat(num_states, 0.6)\n",
    "        self.pi = np.random.rand(num_states)\n",
    "        self.pi = self.pi / np.sum(self.pi)\n",
    "        self.gmms = [GMM(num_mix, 2*num_features) for _ in range(self.num_states)]\n",
    "        \n",
    "    def make_leftright_transmat(self, M, p):\n",
    "        a_ij = np.zeros((M, M))\n",
    "        for i in range(M - 1):\n",
    "            a_ij[i, i] = p\n",
    "            a_ij[i, i + 1] = 1 - p\n",
    "        a_ij[M - 1, M - 1] = 1.0\n",
    "        return a_ij\n",
    "    \n",
    "    def train_gmms(self, data):\n",
    "        state_lengths = len(data) // self.num_states\n",
    "        for i in range(self.num_states):\n",
    "            state_data = data[i * state_lengths:(i + 1) * state_lengths, :]\n",
    "            self.gmms[i].fit(state_data)\n",
    "    \n",
    "    def obs_probs(self, x):\n",
    "        B = np.zeros((self.num_states, x.shape[1]))\n",
    "        for i in range(self.num_states):\n",
    "            B[i, :] = np.exp(self.gmms[i].score_samples(x.T))\n",
    "        return B\n",
    "    \n",
    "    def forward_backward(self, prior, a_ij, B):\n",
    "        M, T = B.shape\n",
    "        scale = np.ones(T)\n",
    "        loglik = 0\n",
    "\n",
    "        alpha = np.zeros((M, T))\n",
    "        beta = np.zeros((M, T))\n",
    "        gamma = np.zeros((M, T))\n",
    "        xiSum = np.zeros((M, M))\n",
    "\n",
    "        t = 0\n",
    "        alpha[:, t], scale[t] = self.normalise(prior * B[:, t])\n",
    "        for t in range(1, T):\n",
    "            m = a_ij.T @ alpha[:, t - 1]\n",
    "            alpha[:, t], scale[t] = self.normalise(m * B[:, t])\n",
    "\n",
    "        if np.any(scale == 0):\n",
    "            loglik = -np.inf\n",
    "        else:\n",
    "            loglik = np.sum(np.log(scale))\n",
    "\n",
    "        beta[:, T - 1] = 1\n",
    "        gamma[:, T - 1], _ = self.normalise(alpha[:, T - 1] * beta[:, T - 1])\n",
    "\n",
    "        for t in range(T - 2, -1, -1):\n",
    "            b = beta[:, t + 1] * B[:, t + 1]\n",
    "            beta[:, t], _ = self.normalise(a_ij @ b)\n",
    "            gamma[:, t], _ = self.normalise(alpha[:, t] * beta[:, t])\n",
    "            xiSum_, _ = self.normalise(a_ij * np.outer(alpha[:, t], b))\n",
    "            xiSum += xiSum_\n",
    "\n",
    "        return alpha, beta, gamma, loglik, xiSum\n",
    "    \n",
    "    def normalise(self, A, dim=None):\n",
    "        if dim is None:\n",
    "            z = np.sum(A)\n",
    "            s = z if z != 0 else 1\n",
    "            M = A / s\n",
    "        elif dim == 1:\n",
    "            z = np.sum(A, axis=0)\n",
    "            s = np.where(z == 0, 1, z)\n",
    "            M = A / s\n",
    "        else:\n",
    "            z = np.sum(A, axis=dim)\n",
    "            s = np.where(z == 0, 1, z)\n",
    "            shape = np.ones(A.ndim, int)\n",
    "            shape[dim] = A.shape[dim]\n",
    "            M = A / s.reshape(shape)\n",
    "        return M, z\n",
    "    \n",
    "    def train_hmm(self, data, pi, max_iter=200, thresh=5e-4):\n",
    "        n_train, T, N = data.shape\n",
    "        M = self.num_states\n",
    "\n",
    "        exp_num_trans = np.zeros((M, M))\n",
    "        exp_num_visits = np.zeros(M)\n",
    "\n",
    "        loglik_sum = 0\n",
    "        prev_loglik = -np.inf\n",
    "        converged = False\n",
    "        iter_count = 1\n",
    "        prior0, _ = self.normalise(pi)\n",
    "        a_ij0 = self.make_leftright_transmat(M, 0.5)\n",
    "        \n",
    "        self.train_gmms(data.reshape(-1, data.shape[-1]))  # Train GMMs\n",
    "        \n",
    "        while not converged and iter_count <= max_iter:\n",
    "            loglik_sum = 0\n",
    "            for i in range(n_train):\n",
    "                x = data[i].T \n",
    "                B = self.obs_probs(x)\n",
    "                alpha, beta, gamma, cur_loglik, xi_sum = self.forward_backward(prior0, a_ij0, B)\n",
    "                loglik_sum += cur_loglik\n",
    "                exp_num_trans += xi_sum\n",
    "                exp_num_visits += gamma[:, 0]\n",
    "            \n",
    "            prior0, _ = self.normalise(exp_num_visits)\n",
    "            a_ij0 = self.mk_stochastic(exp_num_trans)\n",
    "            \n",
    "            d_loglik = abs(loglik_sum - prev_loglik)\n",
    "            avg_loglik = (abs(loglik_sum) + abs(prev_loglik)) / 2\n",
    "\n",
    "            if (d_loglik / avg_loglik) < thresh:\n",
    "                converged = True\n",
    "\n",
    "            prev_loglik = loglik_sum\n",
    "            if iter_count % 10 == 0:\n",
    "                print(f'Iteration {iter_count}, loglik = {loglik_sum}, threshCheck = {d_loglik / avg_loglik}')\n",
    "            iter_count += 1\n",
    "\n",
    "        self.pi = prior0\n",
    "        self.A = a_ij0\n",
    "\n",
    "        return prior0, a_ij0\n",
    "\n",
    "    def mk_stochastic(self, M):\n",
    "        M = np.array(M)\n",
    "        row_sums = M.sum(axis=1)\n",
    "        row_sums[row_sums == 0] = 1\n",
    "        S = M / row_sums[:, np.newaxis]\n",
    "        return S\n",
    "\n",
    "\n",
    "class GMM:\n",
    "    def __init__(self, n_components, n_features):\n",
    "        np.random.seed(seed=52)\n",
    "        self.n_components = n_components\n",
    "        self.n_features = n_features\n",
    "        self.weights = np.ones(n_components) / n_components\n",
    "        self.means = np.random.randn(n_components, n_features)\n",
    "        self.covariances = np.array([np.eye(n_features)] * n_components)\n",
    "        self.epsilon = 1e-6  # Small value to avoid division by zero\n",
    "\n",
    "    def fit(self, X, max_iter=100, tol=1e-6):\n",
    "        n_samples, _ = X.shape\n",
    "        log_likelihood = -np.inf\n",
    "        for _ in range(max_iter):\n",
    "            # E-step\n",
    "            resp = self._estimate_responsibilities(X)\n",
    "            Nk = resp.sum(axis=0) + self.epsilon  # Add epsilon to avoid division by zero\n",
    "            \n",
    "            # M-step\n",
    "            self.weights = Nk / n_samples\n",
    "            self.means = np.dot(resp.T, X) / Nk[:, np.newaxis]\n",
    "            for k in range(self.n_components):\n",
    "                diff = X - self.means[k]\n",
    "                self.covariances[k] = np.dot(resp[:, k] * diff.T, diff) / Nk[k]\n",
    "                self.covariances[k].flat[::self.n_features + 1] += self.epsilon\n",
    "            \n",
    "            # Check for convergence\n",
    "            new_log_likelihood = self._compute_log_likelihood(X)\n",
    "            if abs(new_log_likelihood - log_likelihood) < tol:\n",
    "                break\n",
    "            log_likelihood = new_log_likelihood\n",
    "\n",
    "    def _estimate_responsibilities(self, X):\n",
    "        weighted_log_prob = self._estimate_weighted_log_prob(X)\n",
    "        log_prob_norm = logsumexp(weighted_log_prob, axis=1)\n",
    "        return np.exp(weighted_log_prob - log_prob_norm[:, np.newaxis])\n",
    "\n",
    "    def _estimate_weighted_log_prob(self, X):\n",
    "        return self._estimate_log_prob(X) + np.log(self.weights + self.epsilon)  # Add epsilon to avoid log(0)\n",
    "\n",
    "    def _estimate_log_prob(self, X):\n",
    "        log_prob = np.empty((X.shape[0], self.n_components))\n",
    "        for k in range(self.n_components):\n",
    "            log_prob[:, k] = self._gaussian_log_prob(X, self.means[k], self.covariances[k])\n",
    "        return log_prob\n",
    "\n",
    "    def _gaussian_log_prob(self, X, mean, cov):\n",
    "        n_features = X.shape[1]\n",
    "        log_det = np.linalg.slogdet(cov)[1]\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "        diff = X - mean\n",
    "        return -0.5 * (np.sum(np.dot(diff, inv_cov) * diff, axis=1) + n_features * np.log(2 * np.pi) + log_det)\n",
    "    \n",
    "    def _compute_log_likelihood(self, X):\n",
    "        return np.sum(logsumexp(self._estimate_weighted_log_prob(X), axis=1))\n",
    "\n",
    "    def score_samples(self, X):\n",
    "        return logsumexp(self._estimate_weighted_log_prob(X), axis=1)\n",
    "\n",
    "def logsumexp(a, axis=None):\n",
    "    a_max = np.max(a, axis=axis, keepdims=True)\n",
    "    a_max[~np.isfinite(a_max)] = 0\n",
    "    temp = np.exp(a - a_max)\n",
    "    s = np.sum(temp, axis=axis, keepdims=True)\n",
    "    out = np.log(s)\n",
    "    out += a_max\n",
    "    return out.squeeze(axis)\n",
    "\n",
    "def compute_log_likelihood(model, data):\n",
    "    _, _, _, loglik, _ = model.forward_backward(model.pi, model.A, model.obs_probs(data.T))\n",
    "    return loglik\n",
    "\n",
    "def train_models(data_train, num_states, num_features, num_mix, pi):\n",
    "    models = {}\n",
    "    for label, states in num_states.items():\n",
    "        model = HMM_GMM(num_states=states, num_features=num_features, num_mix=num_mix)\n",
    "        prior, a_ij = model.train_hmm(data_train[label], pi[label], max_iter=100)\n",
    "        model.pi = prior\n",
    "        model.A = a_ij\n",
    "        models[label] = model\n",
    "        print(f'Trained model for {label}')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d6f8d",
   "metadata": {},
   "source": [
    "# Training GMM-HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f9a1d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/rk_bwt6x65g0jskgdx48zmp00000gn/T/ipykernel_15385/1842062081.py:114: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  if (d_loglik / avg_loglik) < thresh:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for Odessa\n",
      "Trained model for turn_off\n",
      "Trained model for turn_on\n",
      "Trained model for time\n",
      "Trained model for play_music\n",
      "Trained model for stop_music\n",
      "Label: Odessa, Accuracy: 100.00%\n",
      "Label: turn_on, Accuracy: 100.00%\n",
      "Label: turn_off, Accuracy: 100.00%\n",
      "Label: play_music, Accuracy: 100.00%\n",
      "Label: stop_music, Accuracy: 100.00%\n",
      "Label: time, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Adjust these parameters accordingly\n",
    "num_features = 13  # #MFCC features\n",
    "num_mix = 3  # #Gaussian mixtures\n",
    "\n",
    "\n",
    "global_mu_5 = { \"Odessa\": [], \"turn_on\":[], \"turn_off\": [], \"play_music\": [], \"stop_music\": [], \"time\": []}\n",
    "global_var_5 = { \"Odessa\": [], \"turn_on\":[], \"turn_off\": [], \"play_music\": [], \"stop_music\": [], \"time\": []}\n",
    "for label, values in data_train.items():\n",
    "    features = np.array([instances for instances_list in values for instances in instances_list])\n",
    "    global_mu_5[label] = np.mean(features, axis=0)\n",
    "    global_var_5[label] = np.var(features, axis=0)\n",
    "\n",
    "num_states = {\n",
    "            \"Odessa\": 14,\n",
    "            \"turn_off\": 14,\n",
    "            \"turn_on\": 15,\n",
    "            \"time\": 15,\n",
    "            \"play_music\": 15,\n",
    "            \"stop_music\": 15\n",
    "        }\n",
    "\n",
    "pi = {\n",
    "            \"Odessa\": np.array([0.82311034, 0.02611798, 0.21077064, 0.61842177, 0.09828447, 0.62013131, 0.05389022, 0.96065406, 0.98042937, 0.52112765, 0.63655334, 0.76475695, 0.76495529, 0.41768558]), #np.ones(num_states[\"Odessa\"]),\n",
    "            \"turn_off\": np.array([0.82311034, 0.02611798, 0.21077064, 0.61842177, 0.09828447, 0.62013131, 0.05389022, 0.96065406, 0.98042937, 0.52112765,0.63655334, 0.76475695, 0.76495529, 0.41768558]),#, 0.76880531,0.42320175, 0.92610357, 0.68192648]),#np.random.rand(num_states[\"turn_off\"]), #np.ones(num_states[\"turn_off\"]),\n",
    "            \"turn_on\": np.array([0.82311034, 0.02611798, 0.21077064, 0.61842177, 0.09828447,0.62013131, 0.05389022, 0.96065406, 0.98042937, 0.52112765,0.63655334, 0.76475695, 0.76495529, 0.41768558, 0.76880531]),#np.random.rand(num_states[\"turn_on\"]),#np.array([0.82311034, 0.02611798, 0.21077064, 0.61842177, 0.09828447, 0.62013131, 0.05389022, 0.96065406, 0.98042937, 0.52112765,0.63655334, 0.76475695, 0.76495529, 0.41768558, 0.76880531]),#np.random.rand(num_states[\"turn_off\"]), #np.ones(num_states[\"turn_off\"]),np.ones(num_states[\"turn_on\"]),\n",
    "            \"time\": np.array([0.36845559, 0.85890986, 0.38049568, 0.09495426, 0.32489071, 0.41511219, 0.74227395, 0.65790887, 0.20131683, 0.80848791,0.78640244, 0.39493964, 0.51061623, 0.79615954, 0.4453775 ]),#np.random.rand(num_states[\"time\"]),#np.ones(num_states[\"time\"]),\n",
    "            \"play_music\": np.array([0.74306691, 0.07874907, 0.48764526, 0.43438864, 0.24605795, 0.86164072, 0.02002256, 0.45082671, 0.04742287, 0.4977275 ,0.858774, 0.33481566, 0.90159003, 0.12288755, 0.15743375]),\n",
    "            \"stop_music\": np.array([0.74306691, 0.07874907, 0.48764526, 0.43438864, 0.24605795, 0.86164072, 0.02002256, 0.45082671, 0.04742287, 0.4977275 ,0.858774, 0.33481566, 0.90159003, 0.12288755, 0.15743375]),#np.ones(num_states[\"stop_music\"]),\n",
    "        }\n",
    "\n",
    "models = train_models(data_train, num_states, num_features, num_mix, pi)\n",
    "accuracy = evaluate_models(models, data_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85efb252",
   "metadata": {},
   "source": [
    "# Start and end point detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46f7104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy(signal, frame_size, method='absolute'):\n",
    "    energy = np.zeros((len(signal) - frame_size + 1,))\n",
    "    for i in range(len(energy)):\n",
    "        frame = signal[i:i+frame_size]\n",
    "        if method == 'absolute':\n",
    "            energy[i] = np.sum(np.abs(frame))\n",
    "        elif method == 'square':\n",
    "            energy[i] = np.sum(frame**2)\n",
    "    #log_energy = np.log10(energy + 1e-10)\n",
    "    return energy\n",
    "\n",
    "# Not using this\n",
    "def estimate_noise_level(log_energy):\n",
    "    Emin = np.min(log_energy)\n",
    "    Emax = Emin + 1 \n",
    "    hist, bin_edges = np.histogram(log_energy, bins=100, range=(Emin, Emax))\n",
    "    most_frequent_bin = np.argmax(hist)\n",
    "    Q = (bin_edges[most_frequent_bin] + bin_edges[most_frequent_bin + 1]) / 2\n",
    "    return Q\n",
    "\n",
    "# Not using this\n",
    "def adjust_log_energy(log_energy, Q):\n",
    "    adjusted_log_energy = log_energy - Q\n",
    "    return adjusted_log_energy\n",
    "\n",
    "def compute_zero_crossings(signal, frame_size):\n",
    "    zero_crossings = np.zeros((len(signal) - frame_size + 1,))\n",
    "    for i in range(len(zero_crossings)):\n",
    "        frame = signal[i:i+frame_size+1]\n",
    "        zero_crossings[i] = 0.5 * np.sum(np.abs(np.sign(frame[1:]) - np.sign(frame[:-1])))\n",
    "    return zero_crossings\n",
    "\n",
    "def set_thresholds(energy, zero_crossings):\n",
    "    IMX = np.max(energy)\n",
    "    IMN = np.min(energy)\n",
    "    ITL = min(0.03 * (IMX - IMN) + IMN, 4 * IMN)\n",
    "    ITU = 5 * ITL\n",
    "\n",
    "    IZC = np.mean(zero_crossings[:100])  # First 100ms for mean ZC\n",
    "    sigma_IZC = np.std(zero_crossings[:100])  # Standard deviation for ZC\n",
    "    IZCT = min(25, IZC + 2 * sigma_IZC)\n",
    "\n",
    "    return ITL, ITU, IZCT\n",
    "\n",
    "def detect_speech_segments(signal, frame_size, sample_rate, k4):\n",
    "    \n",
    "    energy = compute_energy(signal, frame_size, method='absolute')\n",
    "    zero_crossings = compute_zero_crossings(signal, frame_size)\n",
    "    ITL, ITU, IZCT = set_thresholds(energy, zero_crossings)\n",
    "\n",
    "    state = 'silence'\n",
    "    speech_segments = []\n",
    "    start_point = None\n",
    "    min_duration_frames = int(0.075 * sample_rate)\n",
    "\n",
    "    for i in range(len(energy)):\n",
    "        if state == 'silence' and energy[i] > ITL:\n",
    "            state = 'possible_start'\n",
    "            possible_start = i\n",
    "        elif state == 'possible_start' and energy[i] < ITU:\n",
    "            possible_start = i\n",
    "        elif state == 'possible_start' and energy[i] > ITU:\n",
    "            # Start of speech segment\n",
    "            N1 = possible_start  # Potential start point\n",
    "            count_zc = 0\n",
    "            for j in range(max(N1 - 25, 0), N1):\n",
    "                if zero_crossings[j] > IZCT:\n",
    "                    count_zc += 1\n",
    "                    if count_zc == 1:\n",
    "                        N1_prime = j\n",
    "            start_point = N1_prime if count_zc >= 3 else N1\n",
    "            state = 'speech'\n",
    "        elif state == 'speech' and energy[i] < ITU:\n",
    "            state = 'possible_end'\n",
    "        elif state == 'possible_end' and energy[i] < ITL:\n",
    "            # End of speech segment\n",
    "            N2 = i  # Potential end point\n",
    "            count_zc = 0\n",
    "            for j in range(N2, min(N2 + 25, len(energy))):\n",
    "                if zero_crossings[j] > IZCT:\n",
    "                    count_zc += 1\n",
    "                    if count_zc == 1:\n",
    "                        N2_prime = j\n",
    "            end_point = N2_prime if count_zc >= 3 else N2\n",
    "            if start_point is not None:\n",
    "                duration = end_point - start_point\n",
    "                if duration >= min_duration_frames:\n",
    "                    segment = signal[start_point : end_point]\n",
    "                    peak_amplitude = np.max(np.abs(segment))\n",
    "                    if peak_amplitude > k4:\n",
    "                        speech_segments.append((start_point/sample_rate, end_point/sample_rate))\n",
    "            start_point = None\n",
    "            state = 'silence'\n",
    "        elif state == 'speech' and energy[i] > ITL:\n",
    "            # Remain in speech state\n",
    "            continue\n",
    "    \n",
    "    return speech_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad4ae421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_white_noise(signal, snr_db):\n",
    "    # Calculate signal power and required noise power for desired SNR\n",
    "    sig_power = np.mean(signal ** 2)\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    noise_power = sig_power / snr_linear\n",
    "\n",
    "    # Generate white noise\n",
    "    white_noise = np.random.normal(0, np.sqrt(noise_power), signal.shape)\n",
    "\n",
    "    # Add noise to the signal\n",
    "    noisy_signal = signal + white_noise\n",
    "    return noisy_signal\n",
    "\n",
    "def predict_label(models, sequence):\n",
    "    \n",
    "    loglikelihoods = {model_label: compute_log_likelihood(model, sequence) for model_label, model in models.items()}\n",
    "    predicted_label = max(loglikelihoods, key=loglikelihoods.get)\n",
    "    \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53601c69",
   "metadata": {},
   "source": [
    "# Real time detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5e2beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time_speech_detection(frame_size, sample_rate, k4):\n",
    "    \n",
    "\n",
    "    # Initialize variables and state\n",
    "    state = 'silence'\n",
    "    start_point = None\n",
    "    frames = []\n",
    "    speech_segments = []\n",
    "    buffer_length = 5 * sample_rate  # 5 seconds * sample rate samples/second\n",
    "    audio_buffer = np.zeros(buffer_length, dtype='float32')  # Initialize buffer\n",
    "    buffer_index = 0  # Index to keep track of where to insert new audio data\n",
    "    odessa_on = False\n",
    "\n",
    "    def audio_callback(indata, frames, time, status):\n",
    "        nonlocal buffer_index\n",
    "        # Flatten incoming data and add it to the buffer\n",
    "        data_flat = indata.flatten()\n",
    "        # Check if there is enough space left in the buffer; if not, process the current buffer\n",
    "        remaining_buffer_space = buffer_length - buffer_index\n",
    "        if len(data_flat) > remaining_buffer_space:\n",
    "            # Fill the buffer\n",
    "            audio_buffer[buffer_index:buffer_index + remaining_buffer_space] = data_flat[:remaining_buffer_space]\n",
    "            process_buffer(audio_buffer)\n",
    "            # Start filling next buffer\n",
    "            buffer_index = len(data_flat) - remaining_buffer_space\n",
    "            audio_buffer[:buffer_index] = data_flat[remaining_buffer_space:]\n",
    "        else:\n",
    "            # Add incoming data to the buffer\n",
    "            audio_buffer[buffer_index:buffer_index + len(data_flat)] = data_flat\n",
    "            buffer_index += len(data_flat)\n",
    "\n",
    "    def process_buffer(buffer):\n",
    "        # Reset buffer_index for new data accumulation\n",
    "        nonlocal buffer_index, odessa_on, state, start_point, speech_segments\n",
    "        buffer_index = 0\n",
    "        # Here you can process the buffer to detect speech segments\n",
    "        signal = buffer.flatten()\n",
    "        signal = add_white_noise(signal, 30)\n",
    "        print(\"Entered Buffer\")\n",
    "        #np.savetxt('./signal.txt', signal) #saving for debugging\n",
    "\n",
    "        energy = compute_energy(signal, frame_size, method='absolute')\n",
    "        zero_crossings = compute_zero_crossings(signal, frame_size)\n",
    "        ITL, ITU, IZCT = set_thresholds(energy, zero_crossings)\n",
    "\n",
    "        # Similar speech detection logic as before\n",
    "        state = 'silence'\n",
    "        speech_segments = []\n",
    "        start_point = None\n",
    "\n",
    "        min_duration_frames = int(0.075 * sample_rate)\n",
    "\n",
    "        for i in range(len(energy)):\n",
    "            if state == 'silence' and energy[i] > ITL:\n",
    "                state = 'possible_start'\n",
    "                possible_start = i\n",
    "\n",
    "            elif state == 'possible_start' and energy[i] < ITU:\n",
    "                possible_start = i\n",
    "            elif state == 'possible_start' and energy[i] > ITU:\n",
    "                # Start of speech segment\n",
    "                N1 = possible_start  # Potential start point\n",
    "                count_zc = 0\n",
    "                for j in range(max(N1 - 25, 0), N1):\n",
    "                    if zero_crossings[j] > IZCT:\n",
    "                        count_zc += 1\n",
    "                        if count_zc == 1:\n",
    "                            N1_prime = j\n",
    "                start_point = N1_prime if count_zc >= 3 else N1\n",
    "                start_point = max(0, start_point - int(0.3 * sample_rate))  # Adjust start point\n",
    "                state = 'speech'\n",
    "            elif state == 'speech' and energy[i] < ITU:\n",
    "                state = 'possible_end'\n",
    "            elif state == 'possible_end' and energy[i] < ITL:\n",
    "                # End of speech segment\n",
    "                N2 = i  # Potential end point\n",
    "                count_zc = 0\n",
    "                for j in range(N2, min(N2 + 25, len(energy))):\n",
    "                    if zero_crossings[j] > IZCT:\n",
    "                        count_zc += 1\n",
    "                        if count_zc == 1:\n",
    "                            N2_prime = j\n",
    "                end_point = N2_prime if count_zc >= 3 else N2\n",
    "                if start_point is not None:\n",
    "                    duration = end_point - start_point\n",
    "                    if duration >= min_duration_frames:\n",
    "                        segment = signal[start_point : end_point]\n",
    "                        peak_amplitude = np.max(np.abs(segment))\n",
    "                        if peak_amplitude > k4:\n",
    "                            if speech_segments and start_point - speech_segments[-1][1] < 0.4 * sample_rate:\n",
    "                                # Merge with the previous segment\n",
    "                                speech_segments[-1] = (speech_segments[-1][0], end_point)\n",
    "                            else:\n",
    "                                speech_segments.append((start_point, end_point))\n",
    "\n",
    "                start_point = None\n",
    "                state = 'silence'\n",
    "            elif state == 'speech' and energy[i] > ITL:\n",
    "                # Remain in speech state\n",
    "                continue\n",
    "\n",
    "        # Process each finalized speech segment\n",
    "        for (start_point, end_point) in speech_segments:\n",
    "            segment = signal[start_point:end_point]\n",
    "            #np.savetxt('./segment.txt', segment) #saving for debugging\n",
    "            mfcc_features = compute_mfcc(np.array(segment), sample_rate=fs)\n",
    "            delta_mfcc = compute_delta(mfcc_features, 2)\n",
    "            concatenate_features = concatenate_mfcc_deltas(mfcc_features, delta_mfcc, 2)\n",
    "            concatenate_features = np.array(concatenate_features)\n",
    "            pl = predict_label(models, concatenate_features)\n",
    "            print(pl)\n",
    "            if pl == \"Odessa\":\n",
    "                print(\"Listening...\")\n",
    "                sd.play(s/5, sr)\n",
    "                sd.wait()\n",
    "                odessa_on = True\n",
    "            elif odessa_on:\n",
    "                if pl == \"time\":\n",
    "                    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "                    print(f\"The current time is {current_time}.\")\n",
    "                elif pl == \"turn_on\":\n",
    "                    print(\"Glowing light.\")\n",
    "                    light_on_image.show()\n",
    "                elif pl == \"turn_off\":\n",
    "                    print(\"Turning off the light.\")\n",
    "                    light_off_image.show()\n",
    "                elif pl == \"play_music\":\n",
    "                    sd.play(concatenated_music/15, sr_m)\n",
    "                    print(\"Playing low volume music.\")\n",
    "                elif pl == \"stop_music\":\n",
    "                    sd.stop()\n",
    "                    print(\"Stopping the music.\")\n",
    "                odessa_on = False\n",
    "        \n",
    "\n",
    "    # Open a stream with sounddevice\n",
    "    with sd.InputStream(callback=audio_callback, blocksize=frame_size, dtype='float32', samplerate=sample_rate, channels=1):\n",
    "        print(\"Starting real-time speech detection...\")\n",
    "        # Keep the program running to process incoming audio\n",
    "        while True:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e45bf",
   "metadata": {},
   "source": [
    "# Odessa responses build-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e70ace9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "s, sr = librosa.load(\"hello-made-with-Voicemod.mp3\", sr=None)\n",
    "sd.play(s/5, sr)\n",
    "sd.wait()\n",
    "light_on_image = Image.open(\"image_on.jpg\")\n",
    "light_off_image = Image.open(\"image_off.jpg\")\n",
    "\n",
    "music, sr_m= librosa.load(\"music.mp3\", sr=None)\n",
    "\n",
    "sd.play(music/5, sr_m)\n",
    "#sd.wait()\n",
    "sd.stop()\n",
    "concatenated_music = np.concatenate((music/5, music/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2284bf9d",
   "metadata": {},
   "source": [
    "# Real time detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eef4187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting real-time speech detection...\n",
      "Entered Buffer\n",
      "turn_off\n",
      "Entered Buffer\n",
      "turn_on\n",
      "Entered Buffer\n",
      "time\n",
      "Entered Buffer\n",
      "play_music\n",
      "Entered Buffer\n",
      "Odessa\n",
      "Listening...\n",
      "Entered Buffer\n",
      "stop_music\n",
      "Stopping the music.\n",
      "Entered Buffer\n",
      "time\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m k4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Start the real-time detection\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m real_time_speech_detection(frame_size, sample_rate, k4)\n",
      "Cell \u001b[0;32mIn[49], line 140\u001b[0m, in \u001b[0;36mreal_time_speech_detection\u001b[0;34m(frame_size, sample_rate, k4)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting real-time speech detection...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Keep the program running to process incoming audio\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "sample_rate = 16000  \n",
    "frame_size = int(0.01 * sample_rate)  # 10 ms frame size\n",
    "k4 = 0.05\n",
    "# Start the real-time detection\n",
    "real_time_speech_detection(frame_size, sample_rate, k4)\n",
    "#real_time_speech_detection_overlap(frame_size, sample_rate, k4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeaf44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
